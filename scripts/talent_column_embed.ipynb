{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf618ed-5f66-48e2-8d79-30152423b3a3",
   "metadata": {},
   "source": [
    "## Column Embedding Extraction\n",
    "\n",
    "This notebook extract embeddings for the 11 datasets of KE-TALENT. We use the following models:\n",
    "- MPNet `sentence-transformers/all-mpnet-base-v2`\n",
    "- MMTEB SOTA `Alibaba-NLP/gte-Qwen2-7B-instruct`\n",
    "- MMTEB STS SOTA `Lajavaness/bilingual-embedding-large`\n",
    "- (constant embeddings)\n",
    "\n",
    "Please run `scripts/talent_data_preproc.ipynb` beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "883577f4-17c5-40cf-be9e-8deff17ea90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/juyongk/.miniconda3/envs/gcp/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr2/juyongk/graph-concept-prior\n"
     ]
    }
   ],
   "source": [
    "# Run this once at first to work on the project root\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "374d3729-636c-4872-92ca-be590f403959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/juyongk/.miniconda3/envs/gcp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import json\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c38f41e7-c4f9-4469-bb8f-d23bff8c20e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing functions\n",
    "# def split_camel_case_numbers(name):\n",
    "#     # Step 1: Insert space between lowercase->uppercase and uppercase->lowercase transitions\n",
    "#     name = re.sub(r'([a-z])([A-Z])|([A-Z])([A-Z][a-z])', r'\\1\\3 \\2\\4', name)\n",
    "#     # Step 2: Insert space before and after numbers\n",
    "#     name = re.sub(r'(\\d+)', r' \\1 ', name)  # Adds spaces around numbers\n",
    "#     return ' '.join(name.split())  # Removes any extra spaces\n",
    "\n",
    "# def format_name(name):\n",
    "#     name = name.replace('_', ' ')\n",
    "#     name = split_camel_case_numbers(name)\n",
    "#     name = name.lower()\n",
    "#     return name\n",
    "\n",
    "def get_full_desc_sentences(col_name_descs):\n",
    "    ret = []\n",
    "    for name, desc in col_name_descs:\n",
    "        assert name or desc\n",
    "        if not desc or name == desc:\n",
    "            # ret.append(format_name(name))\n",
    "            ret.append(name)\n",
    "        elif not name or 'attribute' in name.lower():\n",
    "            ret.append(desc)\n",
    "        else:\n",
    "            ret.append(name + \" : \" + desc)\n",
    "            # ret.append(format_name(name) + \" : \" + desc)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbce5e91-f999-4f7c-8dc0-c9fd99d345ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "talent_dataset_names = [\n",
    "    \"Abalone_reg\",\n",
    "    \"Diamonds\",\n",
    "    \"Parkinsons_Telemonitoring\",\n",
    "    \"archive_r56_Portuguese\",\n",
    "    \"communities_and_crime\",\n",
    "    \"Bank_Customer_Churn_Dataset\",\n",
    "    \"statlog\",\n",
    "    \"taiwanese_bankruptcy_prediction\",\n",
    "    \"ASP-POTASSCO-classification\",\n",
    "    \"internet_usage\",\n",
    "    \"predict_students_dropout_and_academic_success\",\n",
    "]\n",
    "\n",
    "talent_task_descs = [\n",
    "    \"Predict the age of abalone from physical measurements.\",\n",
    "    \"Predict diamond price based on features such as carat/cut/colour/clarity/size.\",\n",
    "    \"Predict the motor UPDRS score from biomedical voice measurements of people with early-stage Parkinson's disease.\",\n",
    "    \"Predict student performance in secondary education (high school).\",\n",
    "    \"Predict per capita violent crimes.\",\n",
    "    \"Predict if the client has left the bank.\",\n",
    "    \"Predict if a customer has good or bad credit risk.\",\n",
    "    \"Predict the best ASP solver (algorithm) for a given problem instance.\",\n",
    "    \"Predict whether a company will go bankrupt.\",\n",
    "    \"Predict a user's occupation based on demographic and internet usage.\",\n",
    "    \"Predict the student status (dropout, enrolled, and graduate) at the end of the normal duration of the course.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5babc6b-0f64-4adb-8d6b-8de45df8f2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0d4c331-9f30-4fb6-9904-3326742ab812",
   "metadata": {},
   "source": [
    "- Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7037bd-49a9-4025-a767-55edeedb6232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a separate directory to keep Huggingface models. Specify here:\n",
    "cache_dir='/usr1/data/LLM/huggingface/'\n",
    "# cache_dir=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7325f0ee-3568-4960-be3b-cfc6b9aa6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "mpnet_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=cache_dir)\n",
    "mpnet_model = AutoModel.from_pretrained(MODEL_NAME, cache_dir=cache_dir).cuda().eval()\n",
    "\n",
    "def mean_pooling(token_embeddings, attention_mask):\n",
    "    \"\"\"\n",
    "    Perform mean pooling on the token embeddings using the attention mask.\n",
    "    \"\"\"\n",
    "    # Expand the attention mask so it matches the embeddings shape\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    # Sum the token embeddings along the sequence dimension\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, dim=1)\n",
    "    # Count the non-padded tokens per sequence\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n",
    "    # Compute the mean\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "def get_mpnet_embeddings(sentences):\n",
    "    \"\"\"\n",
    "    Given a list of sentences, return a tensor of normalized sentence embeddings.\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    inputs = mpnet_tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = {\n",
    "        k: v.cuda() for k, v in inputs.items()\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Forward pass through model\n",
    "        outputs = mpnet_model(**inputs)\n",
    "    \n",
    "    # Get the last hidden state\n",
    "    token_embeddings = outputs.last_hidden_state\n",
    "    # Perform pooling\n",
    "    sentence_embeddings = mean_pooling(token_embeddings, inputs[\"attention_mask\"])\n",
    "    # (Optional) Normalize embeddings\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1).cpu()\n",
    "    \n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfb5e5f0-22d5-4d24-87f6-4d57a859a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  7.55it/s]\n"
     ]
    }
   ],
   "source": [
    "qwen_tokenizer = AutoTokenizer.from_pretrained('Alibaba-NLP/gte-Qwen2-7B-instruct', cache_dir=cache_dir, trust_remote_code=True)\n",
    "qwen_model = AutoModel.from_pretrained('Alibaba-NLP/gte-Qwen2-7B-instruct', cache_dir=cache_dir, trust_remote_code=True)\n",
    "qwen_model.eval()\n",
    "qwen_model = qwen_model.cuda()\n",
    "qwen_instruction = \"Given the task description of a tabular dataset and a column description, retrive semantically relevant columns.\"\n",
    "qwen_max_length = 8192\n",
    "\n",
    "def last_token_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {qwen_instruction}\\nTask: {task_description}\\nQuery: {query}'\n",
    "\n",
    "def get_qwen_embeddings(sentences, query=False, task_description=None):\n",
    "    if query:\n",
    "        sentences = [get_detailed_instruct(task_description, s) for s in sentences]\n",
    "    ret = []\n",
    "    for s in sentences:\n",
    "        batch_dict = qwen_tokenizer([s], max_length=qwen_max_length, padding=True, truncation=True, return_tensors='pt')\n",
    "        batch_dict = {k: v.cuda() for k, v in batch_dict.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = qwen_model(**batch_dict)\n",
    "        embeddings = last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "        embeddings = embeddings.cpu()\n",
    "        ret.append(embeddings)\n",
    "    ret = torch.concat(ret, dim=0)\n",
    "    ret = F.normalize(ret, p=2, dim=1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c653a18f-16fb-4d6a-b253-57262754e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_model = SentenceTransformer('Lajavaness/bilingual-embedding-large', cache_folder=cache_dir, trust_remote_code=True)\n",
    "sts_model = sts_model.eval().cuda()\n",
    "\n",
    "def get_sts_embeddings(input_sentences):\n",
    "    return torch.tensor(sts_model.encode(input_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316fddac-96ef-4739-a603-1f5965ef8023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aadf252-b83e-44a5-99bb-7b7776b1235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_subdir in talent_dataset_names:\n",
    "    df_desc = pd.read_csv('data/talent/' + dataset_subdir + '/col_desc.csv', keep_default_na=False)\n",
    "    col_name_descs = list(zip(df_desc.name, df_desc.desc))\n",
    "    col_descs = get_full_desc_sentences(col_name_descs)\n",
    "    embeds = get_mpnet_embeddings(col_descs)\n",
    "    torch.save(embeds, 'data/talent/' + dataset_subdir + '/col_embed_mpnet.pt')\n",
    "    \n",
    "    if os.path.exists('data/talent/' + dataset_subdir + '/onehot/col_desc.csv'):\n",
    "        df_desc = pd.read_csv('data/talent/' + dataset_subdir + '/onehot/col_desc.csv', keep_default_na=False)\n",
    "        col_name_descs = list(zip(df_desc.name, df_desc.desc))\n",
    "        col_descs = get_full_desc_sentences(col_name_descs)\n",
    "        embeds = get_mpnet_embeddings(col_descs)\n",
    "        torch.save(embeds, 'data/talent/' + dataset_subdir + '/onehot/col_embed_mpnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9922458-d961-4364-93b6-abb17fc395c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_subdir in talent_dataset_names:\n",
    "    df_desc = pd.read_csv('data/talent/' + dataset_subdir + '/col_desc.csv', keep_default_na=False)\n",
    "    col_name_descs = list(zip(df_desc.name, df_desc.desc))\n",
    "    col_descs = get_full_desc_sentences(col_name_descs)\n",
    "    embeds = get_sts_embeddings(col_descs)\n",
    "    torch.save(embeds, 'data/talent/' + dataset_subdir + '/col_embed_sts.pt')\n",
    "    \n",
    "    if os.path.exists('data/talent/' + dataset_subdir + '/onehot/col_desc.csv'):\n",
    "        df_desc = pd.read_csv('data/talent/' + dataset_subdir + '/onehot/col_desc.csv', keep_default_na=False)\n",
    "        col_name_descs = list(zip(df_desc.name, df_desc.desc))\n",
    "        col_descs = get_full_desc_sentences(col_name_descs)\n",
    "        embeds = get_sts_embeddings(col_descs)\n",
    "        torch.save(embeds, 'data/talent/' + dataset_subdir + '/onehot/col_embed_sts.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1efd6be-b622-4177-807b-f61765c010f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_subdir, task_desc in zip(talent_dataset_names, talent_task_descs):\n",
    "    df_desc = pd.read_csv('data/talent/' + dataset_subdir + '/col_desc.csv', keep_default_na=False)\n",
    "    col_name_descs = list(zip(df_desc.name, df_desc.desc))\n",
    "    col_descs = get_full_desc_sentences(col_name_descs)\n",
    "    query_embeds = get_qwen_embeddings(col_descs, query=True, task_description=task_desc)\n",
    "    doc_embeds = get_qwen_embeddings(col_descs, query=False)\n",
    "    torch.save({'query': query_embeds, 'doc': doc_embeds}, 'data/talent/' + dataset_subdir + '/col_embed_qwen.pt')\n",
    "    \n",
    "    if os.path.exists('data/talent/' + dataset_subdir + '/onehot/col_desc.csv'):\n",
    "        df_desc = pd.read_csv('data/talent/' + dataset_subdir + '/onehot/col_desc.csv', keep_default_na=False)\n",
    "        col_name_descs = list(zip(df_desc.name, df_desc.desc))\n",
    "        col_descs = get_full_desc_sentences(col_name_descs)\n",
    "        query_embeds = get_qwen_embeddings(col_descs, query=True, task_description=task_desc)\n",
    "        doc_embeds = get_qwen_embeddings(col_descs, query=False)\n",
    "        torch.save({'query': query_embeds, 'doc': doc_embeds}, 'data/talent/' + dataset_subdir + '/onehot/col_embed_qwen.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db9c64f9-9fe0-4c22-82ae-94eb8c6752de",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "for dataset_subdir in talent_dataset_names:\n",
    "    df_desc = pd.read_csv('data/talent/' + dataset_subdir + '/col_desc.csv', keep_default_na=False)\n",
    "    embeds = torch.ones((len(df_desc), embed_dim), dtype=torch.float32) + torch.randn((len(df_desc), embed_dim)) * 0.01\n",
    "    embeds = F.normalize(embeds, p=2, dim=1)\n",
    "    torch.save(embeds, 'data/talent/' + dataset_subdir + '/col_embed_unif.pt')\n",
    "    \n",
    "    if os.path.exists('data/talent/' + dataset_subdir + '/onehot/col_desc.csv'):\n",
    "        df_desc = pd.read_csv('data/talent/' + dataset_subdir + '/onehot/col_desc.csv', keep_default_na=False)\n",
    "        embeds = torch.ones((len(df_desc), embed_dim), dtype=torch.float32) + torch.randn((len(df_desc), embed_dim)) * 0.01\n",
    "        embeds = F.normalize(embeds, p=2, dim=1)\n",
    "        torch.save(embeds, 'data/talent/' + dataset_subdir + '/onehot/col_embed_unif.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f16aec2-be27-48e2-8695-46550c0ad682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20bf343a-1cd9-4103-80f0-4cdea19de8c5",
   "metadata": {},
   "source": [
    "### Visualize the concept kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2867df09-2960-494b-a82e-852a7e2d3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_subdir = talent_dataset_names[0]\n",
    "use_orig_format = False\n",
    "\n",
    "dataset_subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd2741f-3028-44bd-b5cc-4e58d53a04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('data/talent/' + dataset_subdir + '/onehot/col_desc.csv') and (not use_orig_format):\n",
    "    orig_embed = torch.load(f'data/talent/{dataset_subdir}/onehot/col_embed_mpnet.pt', weights_only=False)\n",
    "    sts_embed = torch.load(f'data/talent/{dataset_subdir}/onehot/col_embed_sts.pt', weights_only=False)\n",
    "    qwen_embed = torch.load(f'data/talent/{dataset_subdir}/onehot/col_embed_qwen.pt', weights_only=False)\n",
    "    info = json.load(open(f'data/talent/{dataset_subdir}/onehot/info.json'))\n",
    "    df_desc = pd.read_csv(f'data/talent/{dataset_subdir}/onehot/col_desc.csv', keep_default_na=False)\n",
    "else:\n",
    "    orig_embed = torch.load(f'data/talent/{dataset_subdir}/col_embed_mpnet.pt', weights_only=False)\n",
    "    sts_embed = torch.load(f'data/talent/{dataset_subdir}/col_embed_sts.pt', weights_only=False)\n",
    "    qwen_embed = torch.load(f'data/talent/{dataset_subdir}/col_embed_qwen.pt', weights_only=False)\n",
    "    info = json.load(open(f'data/talent/{dataset_subdir}/info.json'))\n",
    "    df_desc = pd.read_csv(f'data/talent/{dataset_subdir}/col_desc.csv', keep_default_na=False)\n",
    "col_name_descs = list(zip(df_desc.name, df_desc.desc))\n",
    "col_sents = get_full_desc_sentences(col_name_descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e5e852-ba10-4de3-b98b-8ae18ad592c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee84e9-2859-4780-870d-f65cc1ab90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = qwen_embed['doc'] @ qwen_embed['query'].T\n",
    "D = W.sum(dim=0, keepdims=True) ** -1\n",
    "T = W * D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f447a-1814-4ddd-b794-2bdd1bf3ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = torch.linalg.eig(T)\n",
    "eig_indices = torch.argsort(eig_vals.abs(), descending=True)\n",
    "eig_vals, eig_vecs = eig_vals[eig_indices], eig_vecs[:, eig_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4a674-0288-457e-891f-e9b1938f46e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(eig_vals[0].real, torch.tensor(1.0)), \"First eigen value != 1.0\"\n",
    "assert torch.allclose(eig_vals[0].imag, torch.tensor(0.0)), \"First eigen value != 1.0\"\n",
    "pi = eig_vecs[:, 0].real\n",
    "pi = pi.abs() / pi.norm(p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec53c0-3658-4971-b9e9-29a03e7dab54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6597cdd-829f-4499-a345-7a8389bff1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_score = orig_embed @ orig_embed.T\n",
    "sts_score = sts_embed @ sts_embed.T\n",
    "qwen_score = qwen_embed['query'] @ qwen_embed['doc'].T\n",
    "qwen_score_norm = (qwen_score + qwen_score.T)/2\n",
    "d = qwen_score_norm[range(len(qwen_score)),range(len(qwen_score))] ** -0.5\n",
    "qwen_score_norm = d.unsqueeze(1) * d.unsqueeze(0) * qwen_score_norm\n",
    "qwen_embed_avg = F.normalize(qwen_embed['query']+qwen_embed['doc'], p=2, dim=1)\n",
    "qwen_score2 = qwen_embed_avg @ qwen_embed_avg.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203bafe9-01dd-4228-a5c0-d585f68bcf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Orig min:', orig_score.min(), 'max:', orig_score.max())\n",
    "print('STS min:', sts_score.min(), 'max:', sts_score.max())\n",
    "print('Qwen min:', qwen_score.min(), 'max:', qwen_score.max())\n",
    "print('Qwen norm min:', qwen_score_norm.min(), 'max:', qwen_score_norm.max())\n",
    "print('Qwen2 min:', qwen_score2.min(), 'max:', qwen_score2.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872707fd-bc65-4e1b-85ab-095a2f0f6b8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a547377a-d7de-4b89-8b85-f19af3b68827",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(orig_score, vmin=-1.0, vmax=1.0, cmap='bwr')\n",
    "plt.yticks(range(len(orig_score)), df_desc.name, fontsize=6)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ffbf0a-05d6-4d97-90bd-51aae263d801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(sts_score, vmin=-1.0, vmax=1.0, cmap='bwr')\n",
    "plt.yticks(range(len(orig_score)), df_desc.name, fontsize=6)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13522a72-22cd-4f8b-912e-681790ecd768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(qwen_score, vmin=-1.0, vmax=1.0, cmap='bwr')\n",
    "plt.yticks(range(len(orig_score)), df_desc.name, fontsize=6)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7e989-21f9-4c6e-9d38-7f8c2bdfaeec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(qwen_score_norm, vmin=-1.0, vmax=1.0, cmap='bwr')\n",
    "plt.yticks(range(len(orig_score)), df_desc.name, fontsize=6)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d7314-a821-40ce-9d93-37ab37102fde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(qwen_score2, vmin=-1.0, vmax=1.0, cmap='bwr')\n",
    "plt.yticks(range(len(orig_score)), df_desc.name, fontsize=6)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4cc614-0dcd-4007-85fc-a6df6c84f052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d9e1c3f-8670-4fc2-90ef-bd0026873e45",
   "metadata": {},
   "source": [
    "## Extract preprocessed input\n",
    "- Save preprocessed input (cat and num columns concatenated) into a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d07c2fc-39b9-4f62-9f3e-ad13cd67c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcp.datasets import load_dataset\n",
    "from gcp.models.base import BaseDeepModel\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6211c788-8ea5-4e2d-8ed2-ca5322ee6bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One-hot converted dataset does not exists. Fall back to the original\n",
      "One-hot converted dataset does not exists. Fall back to the original\n",
      "One-hot converted dataset does not exists. Fall back to the original\n",
      "One-hot converted dataset does not exists. Fall back to the original\n",
      "One-hot converted dataset does not exists. Fall back to the original\n",
      "One-hot converted dataset does not exists. Fall back to the original\n"
     ]
    }
   ],
   "source": [
    "for dataset_subdir in talent_dataset_names:\n",
    "    conf = OmegaConf.load('configs/dataset/talent/' + dataset_subdir + '.yaml')\n",
    "    conf.data_common.use_onehot = True\n",
    "    conf.params.train = conf.data_common\n",
    "    conf.params.val = conf.data_common\n",
    "    conf.params.test = conf.data_common\n",
    "    \n",
    "    train_dataset = load_dataset(conf, 'train')\n",
    "    val_dataset = load_dataset(conf, 'val')\n",
    "    test_dataset = load_dataset(conf, 'test')\n",
    "    \n",
    "    # embed = train_dataset.kg.x.shape\n",
    "    metadata = train_dataset.metadata\n",
    "    \n",
    "    model = BaseDeepModel(task_type=metadata['task_type'], num_classes=metadata['task_type'], n_num_features=metadata['n_num_features'], n_cat_features=metadata['n_cat_features'], kg=None, metadata=metadata)\n",
    "    model.data_preproc(train_dataset)\n",
    "    model.data_preproc(val_dataset)\n",
    "    model.data_preproc(test_dataset)\n",
    "\n",
    "    for split, dataset in [('train', train_dataset), ('val', val_dataset), ('test', test_dataset)]:\n",
    "        X = [dataset.X_num, dataset.X_cat]\n",
    "        X = np.concat([t for t in X if t is not None], axis=1)\n",
    "        np.save('data/talent/' + dataset_subdir + f'/X_{split}.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060eb2f9-204b-462c-9636-e650fff6c4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
